{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69f88e6",
   "metadata": {},
   "source": [
    "# Comparison between training Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5e74d",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7fc201b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [-1.78718199e+09 -9.33407527e+08 -1.80270728e+11 -3.57805653e+09\n",
      " -2.23619107e+09]\n",
      "Mean Squared Error (Cross-Validation): 37761112942.04208\n",
      "Mean Squared Error: 1574265220.4045472\n",
      "R-squared: -1.1894811699177326e+32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "\n",
    "\n",
    "# Load your dataset from CSV files\n",
    "train_data_path = 'C:\\\\Users\\\\moham\\\\Desktop\\\\Apprentissage auto\\\\train.csv'\n",
    "test_data_path = 'C:\\\\Users\\\\moham\\\\Desktop\\\\Apprentissage auto\\\\test.csv'\n",
    "\n",
    "\n",
    "# Assuming your CSV files have a header, if not, set header=None in read_csv\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_data.drop('Price', axis=1)  # Features\n",
    "y_train = train_data['Price']  # Target variable\n",
    "\n",
    "X_test = test_data.drop('Price', axis=1)  # Features\n",
    "y_test = test_data['Price']  # Target variable\n",
    "\n",
    "# Handle missing values in the target variable\n",
    "y_train = y_train.fillna(y_train.mean())  # You can use other imputation strategies\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = ['Prod. year', 'Cylinders', 'Airbags']\n",
    "categorical_features = ['Manufacturer', 'Model', 'Category', 'Fuel type', 'Gear box type', 'Drive wheels', 'Doors', 'Wheel', 'Color', 'Leather interior']\n",
    "\n",
    "# Create transformers for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create a preprocessor using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessor and regressor\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Handle missing values in the target variable for the test set\n",
    "y_test = y_test.fillna(y_train.mean())  # Use the mean from the training set\n",
    "\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)  # Adjust the number of splits as needed\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv)\n",
    "\n",
    "# Display the cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean Squared Error (Cross-Validation):\", -cv_scores.mean())\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ...\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, predictions)\n",
    "print(f'R-squared: {r_squared}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14ca51",
   "metadata": {},
   "source": [
    "# K nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf49ca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [-7.33356281e+09 -7.39367758e+09 -1.80168647e+11 -7.30735588e+09\n",
      " -7.31765448e+09]\n",
      "Mean Squared Error (Cross-Validation): 41904179580.14286\n",
      "Mean Squared Error: 3572969736.3766427\n",
      "R-squared: -2.699659604379624e+32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "\n",
    "\n",
    "# Load your dataset from CSV files\n",
    "train_data_path = 'C:\\\\Users\\\\moham\\\\Desktop\\\\Apprentissage auto\\\\train.csv'\n",
    "test_data_path = 'C:\\\\Users\\\\moham\\\\Desktop\\\\Apprentissage auto\\\\test.csv'\n",
    "\n",
    "\n",
    "# Assuming your CSV files have a header, if not, set header=None in read_csv\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_data.drop('Price', axis=1)  # Features\n",
    "y_train = train_data['Price']  # Target variable\n",
    "\n",
    "X_test = test_data.drop('Price', axis=1)  # Features\n",
    "y_test = test_data['Price']  # Target variable\n",
    "\n",
    "# Handle missing values in the target variable\n",
    "y_train = y_train.fillna(y_train.mean())  # You can use other imputation strategies\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = ['Prod. year', 'Cylinders', 'Airbags']\n",
    "categorical_features = ['Manufacturer', 'Model', 'Category', 'Fuel type', 'Gear box type', 'Drive wheels', 'Doors', 'Wheel', 'Color', 'Leather interior']\n",
    "\n",
    "# Create transformers for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create a preprocessor using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "\n",
    "# Create a pipeline with preprocessor and KNN regressor\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=5))  # You can adjust the number of neighbors (n_neighbors)\n",
    "])\n",
    "\n",
    "\n",
    "# Handle missing values in the target variable for the test set\n",
    "y_test = y_test.fillna(y_train.mean())  # Use the mean from the training set\n",
    "\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)  # Adjust the number of splits as needed\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv)\n",
    "\n",
    "# Display the cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean Squared Error (Cross-Validation):\", -cv_scores.mean())\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ...\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, predictions)\n",
    "print(f'R-squared: {r_squared}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ad04f",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ec6244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [-1.05160231e+08 -1.59157990e+08 -1.80135869e+11 -1.24457187e+11\n",
      " -1.96862623e+10]\n",
      "Mean Squared Error (Cross-Validation): 64908727299.34157\n",
      "Mean Squared Error: 30871722170.718826\n",
      "R-squared: -2.332601376759461e+33\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "# Load your dataset from CSV files\n",
    "train_data_path = 'C:\\\\Users\\\\moham\\\\Desktop\\\\Apprentissage auto\\\\train.csv'\n",
    "test_data_path = 'C:\\\\Users\\\\moham\\\\Desktop\\\\Apprentissage auto\\\\test.csv'\n",
    "\n",
    "\n",
    "# Assuming your CSV files have a header, if not, set header=None in read_csv\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_data.drop('Price', axis=1)  # Features\n",
    "y_train = train_data['Price']  # Target variable\n",
    "\n",
    "X_test = test_data.drop('Price', axis=1)  # Features\n",
    "y_test = test_data['Price']  # Target variable\n",
    "\n",
    "# Handle missing values in the target variable\n",
    "y_train = y_train.fillna(y_train.mean())  # You can use other imputation strategies\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = ['Prod. year', 'Cylinders', 'Airbags']\n",
    "categorical_features = ['Manufacturer', 'Model', 'Category', 'Fuel type', 'Gear box type', 'Drive wheels', 'Doors', 'Wheel', 'Color', 'Leather interior']\n",
    "\n",
    "# Create transformers for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create a preprocessor using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))  # You can adjust the number of trees (n_estimators) and other hyperparameters\n",
    "])\n",
    "\n",
    "\n",
    "# Handle missing values in the target variable for the test set\n",
    "y_test = y_test.fillna(y_train.mean())  # Use the mean from the training set\n",
    "\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)  # Adjust the number of splits as needed\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv)\n",
    "\n",
    "# Display the cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean Squared Error (Cross-Validation):\", -cv_scores.mean())\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ...\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, predictions)\n",
    "print(f'R-squared: {r_squared}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d6f212",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d97ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "\n",
    "# Load your dataset from CSV files\n",
    "train_data_path = 'C:\\\\Users\\\\moham\\\\Desktop\\\\Apprentissage auto\\\\train.csv'\n",
    "test_data_path = 'C:\\\\Users\\\\moham\\\\Desktop\\\\Apprentissage auto\\\\test.csv'\n",
    "\n",
    "\n",
    "# Assuming your CSV files have a header, if not, set header=None in read_csv\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_data.drop('Price', axis=1)  # Features\n",
    "y_train = train_data['Price']  # Target variable\n",
    "\n",
    "X_test = test_data.drop('Price', axis=1)  # Features\n",
    "y_test = test_data['Price']  # Target variable\n",
    "\n",
    "# Handle missing values in the target variable\n",
    "y_train = y_train.fillna(y_train.mean())  # You can use other imputation strategies\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = ['Prod. year', 'Cylinders', 'Airbags']\n",
    "categorical_features = ['Manufacturer', 'Model', 'Category', 'Fuel type', 'Gear box type', 'Drive wheels', 'Doors', 'Wheel', 'Color', 'Leather interior']\n",
    "\n",
    "# Create transformers for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create a preprocessor using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "\n",
    "# Create a pipeline with preprocessor and MLP regressor\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', MLPRegressor(hidden_layer_sizes=(100, ), max_iter=500, random_state=42))  \n",
    "    # You can adjust the hidden_layer_sizes, max_iter, and other hyperparameters\n",
    "])\n",
    "\n",
    "\n",
    "# Handle missing values in the target variable for the test set\n",
    "y_test = y_test.fillna(y_train.mean())  # Use the mean from the training set\n",
    "\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)  # Adjust the number of splits as needed\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv)\n",
    "\n",
    "# Display the cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean Squared Error (Cross-Validation):\", -cv_scores.mean())\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ...\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, predictions)\n",
    "print(f'R-squared: {r_squared}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f31c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
